library(tidyverse)
library(cleaninginspectoR)
library(openxlsx)
df <- read.xlsx("./data/november_2020.xlsx")
issues <- inspect_all(df)
View(issues)
rm(list = ls())
library(tidyverse)
library(cleaninginspectoR)
library(openxlsx)
df <- read.xlsx("./data/december_2020.xlsx")
issues <- inspect_all(df)
View(issues)
## R Validation
rm(list = ls())
library(tidyverse)
library(cleaninginspectoR)
library(openxlsx)
# load analysis files
data <-"./input/CAR1902_HSM_dataset_fev2021_good"
sheets <- openxlsx::getSheetNames(data)
SheetList <- lapply(sheets,openxlsx::read.xlsx,xlsxFile=data)
# load analysis files
data <-"./input/CAR1902_HSM_dataset_fev2021_good.xlsm"
sheets <- openxlsx::getSheetNames(data)
SheetList <- lapply(sheets,openxlsx::read.xlsx,xlsxFile=data)
names(SheetList) <- sheets
## R Validation
rm(list = ls())
library(tidyverse)
library(cleaninginspectoR)
library(openxlsx)
# load analysis files
data <-"./data/CAR1902_HSM_dataset_fev2021_good.xlsm"
sheets <- openxlsx::getSheetNames(data)
SheetList <- lapply(sheets,openxlsx::read.xlsx,xlsxFile=data)
names(SheetList) <- sheets
View(SheetList)
clean <- SheetList[[5]]
clean_log <- SheetList[[6]]
del <- SheetList[[7]]
## check issues
issues <- inspect_all(clean)
View(issues)
clean_red <- select(clean, c("index", "uuid"))
View(clean)
clean_red <- select(clean, c("_index", "uuid"))
View(issues)
issues <- left_join(issues, clean_red, c("index" = "_index"))
write.csv(issues, paste0("./hsm_issues_",lubridate::today(),".csv"))
check_time <- function(data, duration_threshold_lower, duration_threshold_upper){
## Input sanitation
if(!is.data.frame(data))stop("data needs to be a dataframe!")
if(!("start" %in% names(data)))stop("data needs to have a column called 'start' for this function work")
if(!("end" %in% names(data)))stop("data needs to have a column called 'end' for this function work")
## pick apart the date and time parts of the start and end columns and identify those survey completed on different days
df_col_separated <- data %>% separate(start, c("start_date", "start_time"), "T") %>%
separate(end, c("end_date", "end_time"), "T")
df_col_separated$days_diff <- difftime(as.POSIXct(df_col_separated$end_date), as.POSIXct(df_col_separated$start_date), units="days")
same_date <- df_col_separated[((as.numeric(df_col_separated$days_diff))==0),]
different_date <- df_col_separated[((as.numeric(df_col_separated$days_diff))>0),]
#Making time into numeric so that calculations can be done
same_date$start_time <- round(as.difftime(same_date$start_time, units = "mins"),2)
same_date$end_time <- round(as.difftime(same_date$end_time, units = "mins"),2)
same_date$duration_min <- as.numeric(same_date$end_time-same_date$start_time)
same_date$time_short_flag <- ifelse(same_date$duration_min<=duration_threshold_lower,1,0)
same_date$time_long_flag <- ifelse(same_date$duration_min>=duration_threshold_upper,1,0)
## Add Issue column
same_date <- mutate(same_date, issue_type = ifelse((time_short_flag >= 1), "form duration too short",
ifelse((time_long_flag >= 1), "form duration too long", "form duration is ok")))
## seperate the filtering into those surveys that are too long and those that are too short
#too_short <- same_date %>% dplyr::filter(time_short_flag == 1)
#too_short$issue_type <- "form duration too short"
#too_long <- same_date %>% dplyr::filter(time_long_flag == 1)
#too_long$issue_type <- "form duration too long"
## bind and reformat the two culprits !!!
#time_problems <- rbind(too_short, too_long)
time_problems <- dplyr::filter(same_date, issue_type != "form duration is ok")
time_problems <- mutate(time_problems, status_name= ifelse(status == "yes", "refugee", "host community"))
if(nrow(same_date)>=1){
colnames(time_problems)[grep("uuid", colnames(time_problems))] <- "uuid"
#    time_problems$enumerator <- time_problems$enumerator
#    time_problems$sub_county_div <- time_problems$sub_county_div
time_problems$status_name <- time_problems$status_name
time_problems$variable <- "Completion Duration (min)"
time_problems$has_issue <- "TRUE"
time_problems$issue_type <- time_problems$issue_type
#
#
} else {
#
#    time_problems$enumerator <- as.character()
#    time_problems$sub_county_div <- as.character()
time_problems$status_name <- as.character()
time_problems$variable <- as.character()
time_problems$has_issue <- as.character()
time_problems$issue_type <- as.character()
#
}
#
#
time_grab <- time_problems %>% dplyr::select(uuid, status_name, duration_min, variable,	has_issue,	issue_type)
names(time_grab) <- c("uuid", "status",	"value",	"variable",	"has_issue",	"issue_type")
return(time_grab)
}
## check time
time <- check_time(clean, "10", "60")
check_time <- function(data, duration_threshold_lower, duration_threshold_upper){
## Input sanitation
if(!is.data.frame(data))stop("data needs to be a dataframe!")
if(!("start" %in% names(data)))stop("data needs to have a column called 'start' for this function work")
if(!("end" %in% names(data)))stop("data needs to have a column called 'end' for this function work")
## pick apart the date and time parts of the start and end columns and identify those survey completed on different days
df_col_separated <- data %>% separate(start, c("start_date", "start_time"), "T") %>%
separate(end, c("end_date", "end_time"), "T")
df_col_separated$days_diff <- difftime(as.POSIXct(df_col_separated$end_date), as.POSIXct(df_col_separated$start_date), units="days")
same_date <- df_col_separated[((as.numeric(df_col_separated$days_diff))==0),]
different_date <- df_col_separated[((as.numeric(df_col_separated$days_diff))>0),]
#Making time into numeric so that calculations can be done
same_date$start_time <- round(as.difftime(same_date$start_time, units = "mins"),2)
same_date$end_time <- round(as.difftime(same_date$end_time, units = "mins"),2)
same_date$duration_min <- as.numeric(same_date$end_time-same_date$start_time)
same_date$time_short_flag <- ifelse(same_date$duration_min<=duration_threshold_lower,1,0)
same_date$time_long_flag <- ifelse(same_date$duration_min>=duration_threshold_upper,1,0)
## Add Issue column
same_date <- mutate(same_date, issue_type = ifelse((time_short_flag >= 1), "form duration too short",
ifelse((time_long_flag >= 1), "form duration too long", "form duration is ok")))
## seperate the filtering into those surveys that are too long and those that are too short
#too_short <- same_date %>% dplyr::filter(time_short_flag == 1)
#too_short$issue_type <- "form duration too short"
#too_long <- same_date %>% dplyr::filter(time_long_flag == 1)
#too_long$issue_type <- "form duration too long"
## bind and reformat the two culprits !!!
#time_problems <- rbind(too_short, too_long)
time_problems <- dplyr::filter(same_date, issue_type != "form duration is ok")
# time_problems <- mutate(time_problems, status_name= ifelse(status == "yes", "refugee", "host community"))
if(nrow(same_date)>=1){
colnames(time_problems)[grep("uuid", colnames(time_problems))] <- "uuid"
#    time_problems$enumerator <- time_problems$enumerator
#    time_problems$sub_county_div <- time_problems$sub_county_div
#    time_problems$status_name <- time_problems$status_name
time_problems$variable <- "Completion Duration (min)"
time_problems$has_issue <- "TRUE"
time_problems$issue_type <- time_problems$issue_type
#
#
} else {
#
#    time_problems$enumerator <- as.character()
#    time_problems$sub_county_div <- as.character()
#    time_problems$status_name <- as.character()
time_problems$variable <- as.character()
time_problems$has_issue <- as.character()
time_problems$issue_type <- as.character()
#
}
#
#
time_grab <- time_problems %>% dplyr::select(uuid, duration_min, variable,	has_issue,	issue_type)
names(time_grab) <- c("uuid",	"value",	"variable",	"has_issue",	"issue_type")
return(time_grab)
}
## check time
time <- check_time(clean, "10", "60")
View(time)
timec <- SheetList[[4]]
View(timec)
write.csv(issues, paste0("./hsm_time issues_",lubridate::today(),".csv"))
write.csv(time, paste0("./hsm_time issues_",lubridate::today(),".csv"))
View(del)
## check del
delc <- anti_join(del, clean, "uuid")
## check del
delc <- anti_join(clean, del, "uuid")
## check del
delc <- semi_join(clean, del, "uuid")
## check del
delc <- semi_join(del, clean,  "uuid")
View(delc)
library(tidyverse)
library(cleaninginspectoR)
library(openxlsx)
library(daisy)
# load analysis files
data <-"./data/CAR1902_HSM_dataset_march2021.xlsm"
sheets <- openxlsx::getSheetNames(data)
SheetList <- lapply(sheets,openxlsx::read.xlsx,xlsxFile=data)
names(SheetList) <- sheets
View(SheetList)
source("./check_time.R")
source("./data_falsification.R")
clean <- SheetList[[5]]
clean_log <- SheetList[[6]]
del <- SheetList[[7]]
timec <- SheetList[[4]]
raw <- SheetList[[2]]
## check issues
issues <- inspect_all(clean)
View(issues)
## check time
time <- check_time(clean, "10", "60")
View(time)
write.csv(time, paste0("./hsm_time issues_",lubridate::today(),".csv"))
## check del
delc <- semi_join(del, clean,  "uuid")
View(del)
View(clean)
## check del
delc <- semi_join(del, clean,  "_uuid")
## falsification
tool <- read.xlsx("./data/CAR1902_HSM_KoboQuest_new2021.xlsx")
View(tool)
false1 <- calculateDifferences(clean, tool)
library(daisy)
library(cluster)
false1 <- calculateDifferences(clean, tool)
View(false1)
write.csv(time, paste0("./hsm_falsification issues_",lubridate::today(),".csv"))
View(clean)
false2 <- calculateEnumeratorSimilarity(clean, tool, "q0_1_enqueteur", "lieu_collected_commune")
false2 <- calculateEnumeratorSimilarity(raw tool, "q0_1_enqueteur", "lieu_collected_commune")
false2 <- calculateEnumeratorSimilarity(raw, tool, "q0_1_enqueteur", "lieu_collected_commune")
## falsification
tool <- read.xlsx("./data/CAR1902_HSM_KoboQuest_new2021.xlsx")
write.csv(time, paste0("./hsm_falsification issues_",lubridate::today(),".csv"))
false2 <- calculateEnumeratorSimilarity(raw, tool, "q0_1_enqueteur", "lieu_collected_commune")
View(tool)
View(calculateEnumeratorSimilarity)
View(calculateDifferences)
View(raw)
false2 <- calculateEnumeratorSimilarity(raw, tool, "q0_1_enqueteur", "lieu_collected_commune")
false2 <- calculateEnumeratorSimilarity(raw, tool, "q0_1_enqueteur", "lieu_collected_commune")
false2 <- calculateEnumeratorSimilarity(raw, tool, "q0_1_enqueteur", "lieu_collecte_prefecture")
View(false2)
false2 <- calculateEnumeratorSimilarity(raw, tool, "q0_1_enqueteur", "lieu_collecte_commune")
View(false2)
write.csv(false1, paste0("./hsm_falsification issues_",lubridate::today(),".csv"))
false2 <- calculateEnumeratorSimilarity(raw, tool, "q0_1_enqueteur", "info_loc_H2R")
View(false2)
write.csv(false2, paste0("./hsm_enumerator falsification_",lubridate::today(),".csv"))
## R Validation
rm(list = ls())
library(tidyverse)
library(cleaninginspectoR)
library(openxlsx)
library(cluster)
source("./check_time.R")
source("./data_falsification.R")
# load analysis files
data <-"./data/CAR1902_HSM_dataset_april2021.xlsm"
sheets <- openxlsx::getSheetNames(data)
SheetList <- lapply(sheets,openxlsx::read.xlsx,xlsxFile=data)
names(SheetList) <- sheets
View(SheetList)
clean <- SheetList[[5]]
clean_log <- SheetList[[6]]
del <- SheetList[[7]]
timec <- SheetList[[4]]
raw <- SheetList[[2]]
## check issues
issues <- inspect_all(clean)
View(issues)
## check time
time <- check_time(clean, "10", "60")
View(time)
View(del)
View(clean)
## check del
delc <- semi_join(del, clean,  "_uuid")
## falsification
tool <- read.xlsx("./data/CAR1902_HSM_KoboQuest_new2021.xlsx")
false1 <- calculateDifferences(clean, tool)
write.csv(false1, paste0("./hsm_falsification issues_",lubridate::today(),".csv"))
false2 <- calculateEnumeratorSimilarity(raw, tool, "q0_1_enqueteur", "info_loc_H2R")
View(false2)
false2.1 <- calculateEnumeratorSimilarity(clean, tool, "q0_1_enqueteur", "info_loc_H2R")
View(false2.1)
write.csv(false1, paste0("./hsm_falsification issues_",lubridate::today(),".csv"))
write.csv(false2.1, paste0("./hsm_enumerator falsification_",lubridate::today(),".csv"))
